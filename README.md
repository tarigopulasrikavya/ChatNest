# LLM-Powered Chatbot with FastAPI

This is a simple chatbot application built with FastAPI, integrated with OpenAI’s GPT-3.5 model for natural language processing. The chatbot responds to user messages using OpenAI’s API and is deployed as a REST API.

## Features

- FastAPI backend for handling API requests.
- OpenAI GPT-3.5 model used for generating chatbot responses.
- Supports async operations for scalable performance.
- Built-in exception handling for error management.

## Requirements

- Python 3.9 or higher
- OpenAI API key
- FastAPI
- Uvicorn (for running the server)

## Setup Instructions

1. Clone the repository
`git clone https://github.com/yourusername/fast_api_chatbot.git`
`cd fast_api_chatbot`

2. Create a virtual environment

    You can use either conda or venv to create your environment. If you prefer conda:
`conda create --name chatbot-env python=3.9`
`conda activate chatbot-env`

    Alternatively, if you’re using venv:
`python -m venv chatbot-env`
`source chatbot-env/bin/activate`  # On Windows: chatbot-env\Scripts\activate

3. Install dependencies

    Install the required Python packages via pip:
`pip install -r requirements.txt`

    You will also need an OpenAI API key. You can obtain one from [OpenAI’s website](https://beta.openai.com/signup/).

4. Set up your environment variables
`OPENAI_API_KEY=your-openai-api-key`

5. Run the application

    Start the FastAPI server using uvicorn:
`uvicorn app.main:app --reload`

    This will run the server locally at http://127.0.0.1:8000.

6. Access the API

    You can interact with the chatbot using the /chat endpoint. The API expects a POST request with a JSON payload:

    Request:
    `{"message": "Hello, how are you?"}`

    Response:
    `{"response": "I'm doing well, thank you!"}`

    You can test the API directly from the Swagger UI, which is automatically generated by FastAPI and available at:
http://127.0.0.1:8000/docs

7. Stop the server

    To stop the server, press Ctrl+C in the terminal.

## File Structure

fast_api_chatbot/<br>
├── app/<br>
│   ├── __init__.py        # FastAPI app setup<br>
│   ├── main.py            # FastAPI app setup<br>
│   ├── chatbot.py         # Chatbot logic using OpenAI<br>
│   └── models.py          # Pydantic models for request/response<br>
├── .env                   # Environment variables (OpenAI API key)<br>
├── requirements.txt       # List of dependencies<br>
└── README.md              # Project documentation

## License

This project is licensed under the MIT License - see the LICENSE file for details.